{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2076ca2-ed69-4f07-8546-b53646929df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from datasets import Dataset\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a173a804-807a-4752-8c1f-8b7eb3ec60e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "############################################################\n",
    "# 1. Setup and constants\n",
    "############################################################\n",
    "\n",
    "EMOTIONS = [\"Angry\", \"Happy\", \"Relaxed\", \"Sad\"]\n",
    "\n",
    "label2id = {label: i for i, label in enumerate(EMOTIONS)}\n",
    "id2label = {i: label for label, i in label2id.items()}\n",
    "\n",
    "# Timestamp pattern like [01:23.45]\n",
    "timestamp_pattern = re.compile(r\"\\[\\d{2}:\\d{2}(?:\\.\\d{2})?\\]\")\n",
    "\n",
    "DATASET_DIR = \"NJU_MusicMood_v1.0\"\n",
    "\n",
    "############################################################\n",
    "# 2. Cleaning function (clean text for modeling)\n",
    "############################################################\n",
    "\n",
    "def clean_lyrics(text: str) -> str:\n",
    "    # Remove timestamps like [00:29]\n",
    "    text = timestamp_pattern.sub(\"\", text)\n",
    "\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Normalize quotes\n",
    "    text = text.replace(\"’\", \"'\").replace(\"“\", '\"').replace(\"”\", '\"')\n",
    "\n",
    "    # Remove ellipses and repeated dots\n",
    "    text = re.sub(r\"\\.{2,}\", \" \", text)\n",
    "\n",
    "    # Remove long underscores\n",
    "    text = re.sub(r\"_{2,}\", \" \", text)\n",
    "\n",
    "    # Remove trailing \"end\" markers\n",
    "    text = re.sub(r\"\\bend[.\\s]*$\", \"\", text.strip())\n",
    "\n",
    "    # # Replace newlines with space\n",
    "    # text = text.replace(\"\\n\", \" \")\n",
    "\n",
    "    # Remove special characters except letters, digits, spaces, apostrophes\n",
    "    text = re.sub(r\"[^a-z0-9' ]+\", \" \", text)\n",
    "\n",
    "    # Collapse multiple spaces\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "############################################################\n",
    "# 3. Load dataset\n",
    "############################################################\n",
    "\n",
    "def get_lyrics(path: str) -> str:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        raw = f.read()\n",
    "    return clean_lyrics(raw)\n",
    "\n",
    "def get_lyrics_and_labels(split: str):\n",
    "    texts, labels = [], []\n",
    "    for emotion in EMOTIONS:\n",
    "        folder = os.path.join(DATASET_DIR, emotion, split)\n",
    "\n",
    "        if not os.path.isdir(folder):\n",
    "            continue\n",
    "\n",
    "        for fname in os.listdir(folder):\n",
    "            if fname.lower() == \"info.txt\":\n",
    "                continue\n",
    "            if not fname.endswith(\".txt\"):\n",
    "                continue\n",
    "\n",
    "            path = os.path.join(folder, fname)\n",
    "            text = get_lyrics(path)\n",
    "\n",
    "            if text.strip():\n",
    "                texts.append(text)\n",
    "                labels.append(emotion)\n",
    "\n",
    "    return texts, labels\n",
    "\n",
    "train_texts, train_labels = get_lyrics_and_labels(\"Train\")\n",
    "dev_texts, dev_labels = get_lyrics_and_labels(\"Test\")\n",
    "\n",
    "train_ds = Dataset.from_dict({\n",
    "    \"text\": train_texts,\n",
    "    \"label\": [label2id[l] for l in train_labels]\n",
    "})\n",
    "\n",
    "dev_ds = Dataset.from_dict({\n",
    "    \"text\": dev_texts,\n",
    "    \"label\": [label2id[l] for l in dev_labels]\n",
    "})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f511c087-4047-4c1f-be5c-1e4c865c28be",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "# 4. Helper for evaluation\n",
    "############################################################\n",
    "\n",
    "def print_results(true_labels, predicted_labels):\n",
    "    p, r, f, _ = precision_recall_fscore_support(\n",
    "        true_labels, predicted_labels, average=\"macro\", zero_division=0\n",
    "    )\n",
    "    acc = accuracy_score(true_labels, predicted_labels)\n",
    "\n",
    "    print(\"Macro Precision:\", p)\n",
    "    print(\"Macro Recall:\", r)\n",
    "    print(\"Macro F1:\", f)\n",
    "    print(\"Accuracy:\", acc)\n",
    "\n",
    "\n",
    "############################################################\n",
    "# 5. Position tagging function (START, MID, END)\n",
    "############################################################\n",
    "\n",
    "def position_tag(text):\n",
    "    \"\"\"Tag each token with its position in the song.\n",
    "       First 20 percent = _START\n",
    "       Middle 60 percent = _MID\n",
    "       Last 20 percent = _END\n",
    "    \"\"\"\n",
    "    tokens = text.split()\n",
    "    n = len(tokens)\n",
    "    tagged = []\n",
    "\n",
    "    for i, tok in enumerate(tokens):\n",
    "        ratio = i / n\n",
    "        if ratio < 0.2:\n",
    "            tagged.append(tok + \"_START\")\n",
    "        elif ratio > 0.8:\n",
    "            tagged.append(tok + \"_END\")\n",
    "        else:\n",
    "            tagged.append(tok + \"_MID\")\n",
    "\n",
    "    return \" \".join(tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c69e42fe-5779-482a-b97d-528ffc3cb055",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "def print_results(gold_labels, predicted_labels):\n",
    "    # Overall macro metrics\n",
    "    p, r, f, _ = precision_recall_fscore_support(\n",
    "        gold_labels, predicted_labels, average=\"macro\", zero_division=0\n",
    "    )\n",
    "    acc = accuracy_score(gold_labels, predicted_labels)\n",
    "\n",
    "    print(\"=== Overall (Macro Avg) ===\")\n",
    "    print(\"Precision:\", p)\n",
    "    print(\"Recall:\", r)\n",
    "    print(\"F1:\", f)\n",
    "    print(\"Accuracy:\", acc)\n",
    "    print()\n",
    "\n",
    "    # Per class metrics\n",
    "    p_i, r_i, f_i, _ = precision_recall_fscore_support(\n",
    "        gold_labels, predicted_labels, average=None, zero_division=0\n",
    "    )\n",
    "\n",
    "    print(\"=== Per Emotion (Class) Metrics ===\")\n",
    "    for i, emotion in enumerate(EMOTIONS):\n",
    "        print(f\"{emotion}:\")\n",
    "        print(\"  Precision:\", p_i[i])\n",
    "        print(\"  Recall:   \", r_i[i])\n",
    "        print(\"  F1:       \", f_i[i])\n",
    "    print()  # empty line at the end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a44ac8-ce4a-4ae9-8265-6647dba87464",
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f0c9ef1-51a3-45f5-8c59-05ca82663e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Training Logistic Regression with Position Tags (START/MID/END) ===\n",
      "\n",
      "=== Results with START/MID/END position tagging ===\n",
      "=== Overall (Macro Avg) ===\n",
      "Precision: 0.3902636986855047\n",
      "Recall: 0.40970226440661606\n",
      "F1: 0.39418263460750874\n",
      "Accuracy: 0.38992042440318303\n",
      "\n",
      "=== Per Emotion (Class) Metrics ===\n",
      "Angry:\n",
      "  Precision: 0.45544554455445546\n",
      "  Recall:    0.647887323943662\n",
      "  F1:        0.5348837209302325\n",
      "Happy:\n",
      "  Precision: 0.40963855421686746\n",
      "  Recall:    0.32075471698113206\n",
      "  F1:        0.35978835978835977\n",
      "Relaxed:\n",
      "  Precision: 0.3626373626373626\n",
      "  Recall:    0.32673267326732675\n",
      "  F1:        0.34375\n",
      "Sad:\n",
      "  Precision: 0.3333333333333333\n",
      "  Recall:    0.3434343434343434\n",
      "  F1:        0.3383084577114428\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sultanarazia/miniconda3/envs/nlp_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "############################################################\n",
    "# 6. Vectorize with TF-IDF + train Logistic Regression\n",
    "############################################################\n",
    "\n",
    "print(\"=== Training Logistic Regression with Position Tags (START/MID/END) ===\")\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=50000,\n",
    "    ngram_range=(1, 2)           # unigrams + bigrams improve performance\n",
    ")\n",
    "train_tagged = [position_tag(t) for t in train_texts]\n",
    "dev_tagged = [position_tag(t) for t in dev_texts]\n",
    "X_train = vectorizer.fit_transform(train_tagged)\n",
    "X_dev = vectorizer.transform(dev_tagged)\n",
    "\n",
    "clf = LogisticRegression(\n",
    "    max_iter=2000,\n",
    "    class_weight=\"balanced\",\n",
    "    multi_class=\"multinomial\",\n",
    "    solver=\"lbfgs\"\n",
    ")\n",
    "\n",
    "clf.fit(X_train, train_ds[\"label\"])\n",
    "\n",
    "preds = clf.predict(X_dev)\n",
    "\n",
    "############################################################\n",
    "# 7. Print results\n",
    "############################################################\n",
    "\n",
    "print(\"\\n=== Results with START/MID/END position tagging ===\")\n",
    "print_results(dev_ds[\"label\"], preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e091914-4e73-4598-af18-16d4fbf63b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Training Logistic Regression with Position Tags (START/MID/END) ===\n",
      "\n",
      "=== Emotion based results with START/MID/END position tagging ===\n",
      "=== Overall (Macro Avg) ===\n",
      "Precision: 0.3902636986855047\n",
      "Recall: 0.40970226440661606\n",
      "F1: 0.39418263460750874\n",
      "Accuracy: 0.38992042440318303\n",
      "\n",
      "=== Per Emotion (Class) Metrics ===\n",
      "Angry:\n",
      "  Precision: 0.45544554455445546\n",
      "  Recall:    0.647887323943662\n",
      "  F1:        0.5348837209302325\n",
      "Happy:\n",
      "  Precision: 0.40963855421686746\n",
      "  Recall:    0.32075471698113206\n",
      "  F1:        0.35978835978835977\n",
      "Relaxed:\n",
      "  Precision: 0.3626373626373626\n",
      "  Recall:    0.32673267326732675\n",
      "  F1:        0.34375\n",
      "Sad:\n",
      "  Precision: 0.3333333333333333\n",
      "  Recall:    0.3434343434343434\n",
      "  F1:        0.3383084577114428\n",
      "\n"
     ]
    }
   ],
   "source": [
    "############################################################\n",
    "# 6. Vectorize with TF-IDF + train Logistic Regression\n",
    "############################################################\n",
    "\n",
    "print(\"=== Training Logistic Regression with Position Tags (START/MID/END) ===\")\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=50000,\n",
    "    ngram_range=(1, 2)           # unigrams + bigrams improve performance\n",
    ")\n",
    "\n",
    "X_train = vectorizer.fit_transform(train_tagged)\n",
    "X_dev = vectorizer.transform(dev_tagged)\n",
    "\n",
    "clf = LogisticRegression(\n",
    "    max_iter=2000,\n",
    "    class_weight=\"balanced\",\n",
    "    # multi_class=\"multinomial\",\n",
    "    solver=\"lbfgs\"\n",
    ")\n",
    "\n",
    "clf.fit(X_train, train_ds[\"label\"])\n",
    "\n",
    "preds = clf.predict(X_dev)\n",
    "\n",
    "############################################################\n",
    "# 7. Print emotion based results\n",
    "############################################################\n",
    "\n",
    "print(\"\\n=== Emotion based results with START/MID/END position tagging ===\")\n",
    "print_results(dev_ds[\"label\"], preds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74db0f2e-b107-4e50-a8c3-8fd84c7f72c6",
   "metadata": {},
   "source": [
    "## Separate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "edae0849-c024-472c-b012-0dfdfe580eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_segment(text, segment=\"start\", portion=0.3):\n",
    "    \"\"\"\n",
    "    Extracts a portion of the lyrics.\n",
    "    portion=0.3 means 30 percent of lyrics.\n",
    "    segment can be start, middle, or end.\n",
    "    \"\"\"\n",
    "    tokens = text.split()\n",
    "    n = len(tokens)\n",
    "\n",
    "    if n == 0:\n",
    "        return \"\"\n",
    "\n",
    "    cut = int(n * portion)  # number of tokens per section\n",
    "\n",
    "    if segment == \"start\":\n",
    "        return \" \".join(tokens[:cut])\n",
    "\n",
    "    elif segment == \"middle\":\n",
    "        start = int(n * 0.35)\n",
    "        end = int(n * 0.65)\n",
    "        return \" \".join(tokens[start:end])\n",
    "\n",
    "    elif segment == \"end\":\n",
    "        return \" \".join(tokens[-cut:])\n",
    "\n",
    "    else:\n",
    "        return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36360769-eae1-4899-ae40-fb0ba0e73780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build segmented datasets\n",
    "train_start = [get_segment(t, \"start\") for t in train_ds[\"text\"]]\n",
    "train_middle = [get_segment(t, \"middle\") for t in train_ds[\"text\"]]\n",
    "train_end = [get_segment(t, \"end\") for t in train_ds[\"text\"]]\n",
    "\n",
    "dev_start = [get_segment(t, \"start\") for t in dev_ds[\"text\"]]\n",
    "dev_middle = [get_segment(t, \"middle\") for t in dev_ds[\"text\"]]\n",
    "dev_end = [get_segment(t, \"end\") for t in dev_ds[\"text\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b1447b2-d63e-4047-912c-176844a7ff18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_segment_model(train_texts, dev_texts, train_labels, dev_labels, name=\"\"):\n",
    "    print(f\"\\n=== Training {name} model ===\")\n",
    "\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        max_features=50000,\n",
    "        ngram_range=(1, 2)\n",
    "    )\n",
    "\n",
    "    X_train = vectorizer.fit_transform(train_texts)\n",
    "    X_dev = vectorizer.transform(dev_texts)\n",
    "\n",
    "    clf = LogisticRegression(\n",
    "        max_iter=2000,\n",
    "        class_weight=\"balanced\",\n",
    "        multi_class=\"multinomial\"\n",
    "    )\n",
    "\n",
    "    clf.fit(X_train, train_labels)\n",
    "    preds = clf.predict(X_dev)\n",
    "\n",
    "    print(f\"=== Results ({name}) ===\")\n",
    "    print_results(dev_labels, preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b564995-3f4b-4218-975d-3a070cea935d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training BEGINNING ONLY model ===\n",
      "=== Results (BEGINNING ONLY) ===\n",
      "=== Overall (Macro Avg) ===\n",
      "Precision: 0.3458269076705815\n",
      "Recall: 0.3602639861381833\n",
      "F1: 0.3481884320377146\n",
      "Accuracy: 0.3421750663129973\n",
      "\n",
      "=== Per Emotion (Class) Metrics ===\n",
      "Angry:\n",
      "  Precision: 0.4375\n",
      "  Recall:    0.5915492957746479\n",
      "  F1:        0.5029940119760479\n",
      "Happy:\n",
      "  Precision: 0.4157303370786517\n",
      "  Recall:    0.3490566037735849\n",
      "  F1:        0.37948717948717947\n",
      "Relaxed:\n",
      "  Precision: 0.2911392405063291\n",
      "  Recall:    0.22772277227722773\n",
      "  F1:        0.25555555555555554\n",
      "Sad:\n",
      "  Precision: 0.23893805309734514\n",
      "  Recall:    0.2727272727272727\n",
      "  F1:        0.25471698113207547\n",
      "\n",
      "\n",
      "=== Training MIDDLE ONLY model ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sultanarazia/miniconda3/envs/nlp_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/sultanarazia/miniconda3/envs/nlp_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results (MIDDLE ONLY) ===\n",
      "=== Overall (Macro Avg) ===\n",
      "Precision: 0.4168987689585285\n",
      "Recall: 0.43011603844413143\n",
      "F1: 0.4214992552389918\n",
      "Accuracy: 0.41644562334217505\n",
      "\n",
      "=== Per Emotion (Class) Metrics ===\n",
      "Angry:\n",
      "  Precision: 0.48863636363636365\n",
      "  Recall:    0.6056338028169014\n",
      "  F1:        0.5408805031446541\n",
      "Happy:\n",
      "  Precision: 0.46938775510204084\n",
      "  Recall:    0.4339622641509434\n",
      "  F1:        0.45098039215686275\n",
      "Relaxed:\n",
      "  Precision: 0.3333333333333333\n",
      "  Recall:    0.297029702970297\n",
      "  F1:        0.31413612565445026\n",
      "Sad:\n",
      "  Precision: 0.37623762376237624\n",
      "  Recall:    0.3838383838383838\n",
      "  F1:        0.38\n",
      "\n",
      "\n",
      "=== Training END ONLY model ===\n",
      "=== Results (END ONLY) ===\n",
      "=== Overall (Macro Avg) ===\n",
      "Precision: 0.34643808610400684\n",
      "Recall: 0.36406859195087726\n",
      "F1: 0.3458654058052186\n",
      "Accuracy: 0.34748010610079577\n",
      "\n",
      "=== Per Emotion (Class) Metrics ===\n",
      "Angry:\n",
      "  Precision: 0.3416666666666667\n",
      "  Recall:    0.5774647887323944\n",
      "  F1:        0.4293193717277487\n",
      "Happy:\n",
      "  Precision: 0.40217391304347827\n",
      "  Recall:    0.3490566037735849\n",
      "  F1:        0.37373737373737376\n",
      "Relaxed:\n",
      "  Precision: 0.32941176470588235\n",
      "  Recall:    0.27722772277227725\n",
      "  F1:        0.3010752688172043\n",
      "Sad:\n",
      "  Precision: 0.3125\n",
      "  Recall:    0.25252525252525254\n",
      "  F1:        0.27932960893854747\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sultanarazia/miniconda3/envs/nlp_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate beginning model\n",
    "train_segment_model(\n",
    "    train_start,\n",
    "    dev_start,\n",
    "    train_ds[\"label\"],\n",
    "    dev_ds[\"label\"],\n",
    "    name=\"BEGINNING ONLY\"\n",
    ")\n",
    "\n",
    "# Train and evaluate middle model\n",
    "train_segment_model(\n",
    "    train_middle,\n",
    "    dev_middle,\n",
    "    train_ds[\"label\"],\n",
    "    dev_ds[\"label\"],\n",
    "    name=\"MIDDLE ONLY\"\n",
    ")\n",
    "\n",
    "# Train and evaluate end model\n",
    "train_segment_model(\n",
    "    train_end,\n",
    "    dev_end,\n",
    "    train_ds[\"label\"],\n",
    "    dev_ds[\"label\"],\n",
    "    name=\"END ONLY\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effdb70d-f660-4c6d-b192-2da9161f058b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c0f15b-e310-49a1-b6e2-739137694c44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
